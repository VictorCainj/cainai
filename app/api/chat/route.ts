import { NextRequest, NextResponse } from 'next/server'
import OpenAI from 'openai'
import { chatService } from '@/lib/chat-service'
import { sessionManager } from '@/lib/session'
import { context7Service } from '@/lib/context7-service'
import { supabase } from '@/lib/supabase'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

// Prompt otimizado para super mem√≥ria com GPT-4o + Context7 MCP
const SYSTEM_PROMPT = `Voc√™ √© um assistente especializado em produtividade com SUPER MEM√ìRIA, powered by GPT-4o + Context7 MCP. Voc√™ tem acesso completo ao hist√≥rico da conversa atual e documenta√ß√£o atualizada em tempo real.

**SUAS CAPACIDADES DE MEM√ìRIA:**
üß† **Mem√≥ria Contextual**: Lembro de tudo que foi discutido nesta conversa
üîó **Conex√µes**: Consigo conectar informa√ß√µes de mensagens anteriores
üìã **Continuidade**: Acompanho projetos, tarefas e ideias em andamento
üéØ **Personaliza√ß√£o**: Adapto respostas baseado no seu hist√≥rico e prefer√™ncias
üéì **Aprendizado**: Melhoro com cada intera√ß√£o nossa
üé® **Gera√ß√£o de Imagens**: Posso criar imagens usando DALL-E 3
üìö **Context7 MCP**: Acesso a documenta√ß√£o atualizada de bibliotecas e frameworks em tempo real

**SUAS ESPECIALIDADES:**

üìã **ORGANIZA√á√ÉO DE TAREFAS:**
- Ajudar a priorizar usando m√©todos como Matriz de Eisenhower
- Quebrar projetos grandes em tarefas menores
- Criar cronogramas realistas
- Sugerir ferramentas e metodologias (GTD, Kanban, etc.)
- LEMBRAR de tarefas mencionadas anteriormente

üìù **GEST√ÉO DE INFORMA√á√ïES:**
- Estruturar notas e documentos
- Criar resumos e s√≠nteses
- Organizar conhecimento e aprendizado
- Templates e checklists √∫teis
- CONECTAR informa√ß√µes de conversas passadas

üìÖ **PLANEJAMENTO:**
- Rotinas di√°rias e semanais
- Bloqueio de tempo (time blocking)
- Planejamento de projetos
- Metas SMART
- ACOMPANHAR progressos mencionados antes

üçÖ **T√âCNICAS DE FOCO:**
- Pomodoro e varia√ß√µes
- Deep Work
- Gest√£o de distra√ß√µes
- T√©cnicas de concentra√ß√£o
- ADAPTAR baseado em suas prefer√™ncias j√° mencionadas

üí° **CRIATIVIDADE E AN√ÅLISE:**
- Brainstorming estruturado
- An√°lise de problemas
- Tomada de decis√µes
- Mapas mentais
- EXPANDIR ideias que voc√™ j√° compartilhou

üé® **GERA√á√ÉO DE IMAGENS:**
- Detectar quando o usu√°rio solicita uma imagem
- Criar prompts detalhados para DALL-E 3
- Sugerir melhorias visuais para projetos
- Criar ilustra√ß√µes para conceitos e ideias

üìö **CONTEXT7 MCP - DOCUMENTA√á√ÉO ATUALIZADA:**
- Busco automaticamente documenta√ß√£o atualizada quando voc√™ menciona bibliotecas
- Detecto frameworks e tecnologias em suas perguntas
- Forne√ßo exemplos de c√≥digo com vers√µes atuais
- Evito APIs depreciadas e m√©todos obsoletos
- Bibliotecas suportadas: React, Next.js, Vue, Angular, Node.js, Python, e muito mais

**DETEC√á√ÉO DE SOLICITA√á√ïES DE IMAGEM:**
Se o usu√°rio solicitar uma imagem, foto, desenho, ilustra√ß√£o, logo, design, ou qualquer conte√∫do visual, voc√™ deve responder EXATAMENTE neste formato:

[IMAGEM_SOLICITADA]
Descri√ß√£o detalhada da imagem em ingl√™s para DALL-E 3
[/IMAGEM_SOLICITADA]

Seguido de uma explica√ß√£o em portugu√™s sobre o que ser√° criado.

**COMO USAR SUA SUPER MEM√ìRIA:**

1. **SEMPRE referencie** informa√ß√µes relevantes de mensagens anteriores
2. **CONECTE** a pergunta atual com contexto passado quando relevante
3. **ACOMPANHE** projetos e tarefas em andamento
4. **PERSONALIZE** sugest√µes baseado no que voc√™ j√° aprendeu sobre mim
5. **CONSTRUA** sobre conversas anteriores em vez de come√ßar do zero

**ESTRUTURA DE RESPOSTA:**
- Se relevante, mencione conex√µes com conversas anteriores
- Forne√ßa sugest√µes pr√°ticas e organizadas
- Inclua pr√≥ximos passos espec√≠ficos
- Use formata√ß√£o clara (listas, subt√≠tulos)
- Seja amig√°vel, motivador e contextualizado

**IMPORTANTE SOBRE C√ìDIGOS E EXEMPLOS:**
üöÄ **SEMPRE forne√ßa c√≥digos COMPLETOS** quando solicitado - nunca truncar ou encurtar
üìù **NUNCA use coment√°rios como "// ... resto do c√≥digo ..."** - sempre escreva tudo
üîß **Inclua todos os imports, fun√ß√µes e componentes necess√°rios**
üíØ **C√≥digos devem estar prontos para uso imediato** sem necessidade de "completar"
üìö **Se o c√≥digo for muito extenso, divida em se√ß√µes mas SEMPRE complete cada uma**

**IMPORTANTE**: Use sua mem√≥ria para dar respostas mais inteligentes e personalizadas!`

interface MessageContext {
  role: string
  content: string
  timestamp: Date
}

// Fun√ß√£o para detectar e gerar imagem com DALL-E 3
async function generateImageIfRequested(messageContent: string): Promise<{hasImage: boolean, imageUrl?: string, imagePrompt?: string}> {
  const imageRegex = /\[IMAGEM_SOLICITADA\]([\s\S]*?)\[\/IMAGEM_SOLICITADA\]/
  const match = messageContent.match(imageRegex)
  
  if (!match) {
    return { hasImage: false }
  }

  const imagePrompt = match[1].trim()
  
  try {
    const imageResponse = await openai.images.generate({
      model: "dall-e-3",
      prompt: imagePrompt,
      n: 1,
      size: "1024x1024",
      quality: "standard",
      style: "vivid"
    })

    const imageUrl = imageResponse.data?.[0]?.url
    
    if (imageUrl) {
      return { 
        hasImage: true, 
        imageUrl, 
        imagePrompt 
      }
    }
  } catch (error) {
    // Silent fail
  }
  
  return { hasImage: false }
}

export async function POST(request: NextRequest) {
  let message = ''
  
  try {
    const body = await request.json()
    const bodyData = body
    message = bodyData.message
    const { conversationId, userId, fullContext } = bodyData
    
    // Tentar obter usu√°rio autenticado do Supabase
    const { data: { user }, error: userError } = await supabase.auth.getUser()
    
    // Priorizar usu√°rio autenticado, depois providedUserId, depois sessionManager
    const effectiveUserId = user?.id || userId || sessionManager.getUserId()

    if (!message || !effectiveUserId) {
      return NextResponse.json({ error: 'Message and userId required' }, { status: 400 })
    }

    if (!process.env.OPENAI_API_KEY) {
      return NextResponse.json({ error: 'OpenAI API key not configured' }, { status: 500 })
    }

    // Detectar comandos de resumo
    const lowerMessage = message.toLowerCase().trim()
    const isResumeCommand = lowerMessage.includes('gere um resumo') || 
                          lowerMessage.includes('fa√ßa um resumo') || 
                          lowerMessage.includes('gerar resumo') ||
                          lowerMessage.includes('resumir conversa') ||
                          lowerMessage.includes('fazer resumo') ||
                          lowerMessage === 'resumo' ||
                          lowerMessage.includes('resumir esta conversa') ||
                          lowerMessage.includes('criar resumo')

    if (isResumeCommand && conversationId && !conversationId.startsWith('temp')) {
      // Redirecionar para gera√ß√£o de resumo
      try {
        const summaryResponse = await fetch(`${process.env.NEXT_PUBLIC_SITE_URL || 'http://localhost:3000'}/api/conversations/${conversationId}/generate-summary`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({ userId: effectiveUserId })
        })
        
        const summaryData = await summaryResponse.json()
        
        if (summaryData.success) {
          const summary = summaryData.summary
          const responseText = `üìä **Cronologia da Conversa Gerada**

**Contexto:**
${summary.summaryText}

**Cronologia de A√ß√µes:**
${summary.timeline && summary.timeline.length > 0 
  ? summary.timeline.map((entry: any) => `üïê **${entry.time}** (${entry.period}): ${entry.action}`).join('\n')
  : 'Nenhuma a√ß√£o cronol√≥gica identificada'
}

**An√°lise:**
‚Ä¢ **Sentimento:** ${summary.sentiment === 'positive' ? 'üòä Positivo' : summary.sentiment === 'negative' ? 'üòî Negativo' : 'üòê Neutro'}
‚Ä¢ **Gerado em:** ${new Date(summary.generatedAt).toLocaleString('pt-BR')}

üí° *Cronologia salva automaticamente. Voc√™ pode acess√°-la a qualquer momento atrav√©s do painel lateral ou do bot√£o flutuante.*`

          return NextResponse.json({
            message: responseText,
            conversationId,
            summaryGenerated: true,
            success: true
          })
        } else {
          return NextResponse.json({
            message: "‚ùå **Erro ao gerar resumo**\n\nN√£o foi poss√≠vel gerar o resumo da conversa. Certifique-se de que h√° mensagens suficientes na conversa (m√≠nimo de 2 mensagens).",
            conversationId,
            success: true
          })
        }
      } catch (error) {
        console.error('Erro ao gerar resumo via chat:', error)
        return NextResponse.json({
          message: "‚ùå **Erro de conex√£o**\n\nOcorreu um erro ao tentar gerar o resumo. Tente novamente em alguns instantes.",
          conversationId,
          success: true
        })
      }
    }

    const isServiceHealthy = await chatService.healthCheck()
    
    let conversation: any = null
    let allMessages: any[] = []
    let isTemporaryMode = false

    if (isServiceHealthy) {
      try {
        if (conversationId && !conversationId.startsWith('temp')) {
          const result = await chatService.getConversationWithMessages(conversationId, effectiveUserId)
          conversation = result.conversation
          allMessages = result.messages
        }

        if (!conversation) {
          const title = message.slice(0, 50) + (message.length > 50 ? '...' : '')
          conversation = await chatService.createConversation({
            title,
            userId: effectiveUserId
          })
          
          if (!conversation) {
            conversation = await chatService.createConversationFallback(title)
            isTemporaryMode = true
          }
        }

        if (!isTemporaryMode && conversation && !conversationId?.startsWith('temp')) {
          await chatService.addMessage({
            conversationId: conversation.id,
            role: 'user',
            content: message
          })
        }

      } catch (dbError) {
        isTemporaryMode = true
        conversation = await chatService.createConversationFallback(
          message.slice(0, 50) + (message.length > 50 ? '...' : '')
        )
      }
    } else {
      isTemporaryMode = true
      conversation = await chatService.createConversationFallback(
        message.slice(0, 50) + (message.length > 50 ? '...' : '')
      )
    }

    let contextMessages = []
    
    if (allMessages.length > 0) {
      contextMessages = allMessages
        .filter(msg => msg.role === 'user' || msg.role === 'assistant')
        .map(msg => ({
          role: msg.role as 'user' | 'assistant',
          content: msg.content
        }))
    }
    else if (fullContext && fullContext.length > 0) {
      contextMessages = fullContext
        .filter((msg: MessageContext) => msg.role === 'user' || msg.role === 'assistant')
        .map((msg: MessageContext) => ({
          role: msg.role as 'user' | 'assistant',
          content: msg.content
        }))
    }

    const openAIMessages: Array<{role: 'system' | 'user' | 'assistant', content: string}> = [
      {
        role: 'system' as const,
        content: SYSTEM_PROMPT
      }
    ]

    if (contextMessages.length > 0) {
      const maxContextMessages = 30
      const recentMessages = contextMessages.slice(-maxContextMessages)
      
      if (contextMessages.length > maxContextMessages) {
        openAIMessages.push({
          role: 'system' as const,
          content: `[CONTEXTO HIST√ìRICO]: Esta conversa tem ${contextMessages.length} mensagens no total. Abaixo est√£o as ${recentMessages.length} mais recentes. Use essa informa√ß√£o para dar respostas contextualizadas e personalizadas.`
        })
      }
      
      for (const msg of recentMessages) {
        openAIMessages.push({
          role: msg.role as 'user' | 'assistant',
          content: msg.content
        })
      }
    }

    // Integra√ß√£o Context7 MCP - Buscar documenta√ß√£o relevante
    let context7Documentation = ''
    let context7Info: { librariesDetected: string[], tokensUsed: number } = { 
      librariesDetected: [], 
      tokensUsed: 0 
    }
    
    try {
      const context7Result = await context7Service.processMessage(message)
      context7Documentation = context7Result.documentation
      context7Info = {
        librariesDetected: context7Result.librariesDetected,
        tokensUsed: context7Result.tokensUsed
      }
      
      if (context7Documentation) {
        // Adicionar documenta√ß√£o Context7 ao contexto do sistema
        openAIMessages.push({
          role: 'system' as const,
          content: context7Documentation
        })
      }
    } catch (context7Error) {
      // Falha silenciosa do Context7 - n√£o impede o chat de funcionar
      if (process.env.NODE_ENV === 'development') {
        console.warn('Context7 error:', context7Error)
      }
    }

    openAIMessages.push({
      role: 'user' as const,
      content: message
    })

    const completion = await openai.chat.completions.create({
      model: 'gpt-4o',
      messages: openAIMessages,
      max_tokens: 4096,
      temperature: 0.7,
      top_p: 0.9,
      frequency_penalty: 0.1,
      presence_penalty: 0.1,
    })

    let assistantMessage = completion.choices[0]?.message?.content || 'Desculpe, n√£o consegui processar sua mensagem com minha super mem√≥ria.'

    const imageResult = await generateImageIfRequested(assistantMessage)
    
    let finalMessage = assistantMessage
    let imageUrl = null
    
    if (imageResult.hasImage && imageResult.imageUrl) {
      finalMessage = assistantMessage.replace(/\[IMAGEM_SOLICITADA\][\s\S]*?\[\/IMAGEM_SOLICITADA\]/, '')
      imageUrl = imageResult.imageUrl
      finalMessage = `${finalMessage}\n\nüé® **Imagem gerada com DALL-E 3:**\n*"${imageResult.imagePrompt?.slice(0, 100)}..."*\n\nA imagem foi criada e anexada abaixo!`
    }

    if (!isTemporaryMode && conversation && !conversationId?.startsWith('temp')) {
      await chatService.addMessage({
        conversationId: conversation.id,
        role: 'assistant',
        content: finalMessage + (imageUrl ? `\n\n[IMAGE]:${imageUrl}` : '')
      })
    }

    return NextResponse.json({
      message: finalMessage,
      imageUrl: imageUrl,
      conversationId: conversation.id,
      conversationTitle: conversation.title,
      success: true,
      isTemporary: isTemporaryMode,
      usage: completion.usage,
      model: 'gpt-4o',
      contextUsed: contextMessages.length,
      superMemoryActive: true,
      dalleGenerated: !!imageUrl,
      context7: {
        enabled: !!context7Documentation,
        librariesDetected: context7Info.librariesDetected,
        tokensUsed: context7Info.tokensUsed
      }
    })

  } catch (error) {
    // Log apenas em desenvolvimento
    if (process.env.NODE_ENV === 'development') {
      console.error('Error in chat API:', error)
    }
    
    try {
      if (!process.env.OPENAI_API_KEY) {
        throw new Error('OpenAI API key not configured')
      }

      const completion = await openai.chat.completions.create({
        model: 'gpt-4o',
        messages: [
          {
            role: 'system',
            content: 'Voc√™ √© um assistente de produtividade brasileiro especializado em organiza√ß√£o, planejamento e efici√™ncia. Seja pr√°tico, objetivo e √∫til. Voc√™ tamb√©m pode gerar imagens com DALL-E 3 quando solicitado.'
          },
          {
            role: 'user',
            content: typeof message === 'string' ? message : 'Ol√°! Como posso ajudar com sua produtividade hoje?'
          }
        ],
        max_tokens: 4096,
        temperature: 0.7,
      })

      const assistantMessage = completion.choices[0]?.message?.content || 'Como posso ajudar voc√™ a ser mais produtivo hoje?'

      return NextResponse.json({
        message: assistantMessage,
        conversationId: 'temp-' + Date.now(),
        success: true,
        mode: 'fallback',
        superMemoryActive: false,
        model: 'gpt-4o'
      })

    } catch (fallbackError) {
      return NextResponse.json(
        { 
          error: 'Servi√ßo temporariamente indispon√≠vel',
          details: process.env.NODE_ENV === 'development' ? (error instanceof Error ? error.message : 'Unknown error') : undefined
        },
        { status: 500 }
      )
    }
  }
} 